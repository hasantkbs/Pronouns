# EÄŸitim SorunlarÄ± ve DÃ¼zeltmeler

## ğŸ”´ Tespit Edilen Sorunlar

### 1. YÃ¼ksek WER/CER (99.76% / 82.87%)
- Model hiÃ§ Ã¶ÄŸrenmemiÅŸ
- Label encoding hatasÄ±
- Veri formatÄ± uyumsuzluÄŸu

### 2. Negatif Loss (-0.7099)
- GeÃ§ersiz loss deÄŸeri
- Label encoding sorunu
- CTC loss hesaplama hatasÄ±

## âœ… YapÄ±lan DÃ¼zeltmeler

### 1. Label Encoding DÃ¼zeltmesi

**Ã–nceki (YanlÄ±ÅŸ):**
```python
# Batch olarak tokenize ediliyordu
labels = processor.tokenizer(
    valid_transcripts, 
    return_tensors="pt", 
    padding=True
).input_ids
```

**Yeni (DoÄŸru):**
```python
# Her Ã¶rnek iÃ§in ayrÄ± ayrÄ± tokenize ediliyor
for transcript in valid_transcripts:
    label_ids = processor.tokenizer(transcript).input_ids
    if isinstance(label_ids, torch.Tensor):
        label_ids = label_ids.tolist()
    if isinstance(label_ids[0], list):
        label_ids = label_ids[0]
    label_ids_list.append(label_ids)
```

### 2. Input Values FormatÄ± DÃ¼zeltmesi

**Ã–nceki (YanlÄ±ÅŸ):**
```python
# Batch olarak iÅŸleniyordu
inputs = processor(audio_arrays, ...)
input_values = inputs.input_values  # Tensor
```

**Yeni (DoÄŸru):**
```python
# Her Ã¶rnek iÃ§in ayrÄ± ayrÄ± iÅŸleniyor
for audio in audio_arrays:
    inputs = processor(audio, padding=False, ...)
    input_values_list.append(inputs.input_values[0].tolist())
```

### 3. Loss KontrolÃ¼ Eklendi

```python
# Negatif veya invalid loss kontrolÃ¼
if torch.isnan(loss) or torch.isinf(loss) or loss.item() < 0:
    print(f"âš ï¸  GeÃ§ersiz loss: {loss.item()}, batch atlanÄ±yor.")
    continue
```

### 4. Validation Ä°yileÅŸtirmeleri

- Loss kontrolÃ¼ eklendi
- BoÅŸ tahminler filtreleniyor
- Daha iyi hata yÃ¶netimi
- Debug bilgileri

## ğŸš€ Yeniden EÄŸitim

DÃ¼zeltmelerden sonra yeniden eÄŸitim yapÄ±n:

```bash
# Eski modeli temizle (opsiyonel)
rm -rf data/models/personalized_models/Furkan/checkpoints

# Yeniden eÄŸitim
python3 train_adapter.py Furkan
```

## ğŸ“Š Beklenen Ä°yileÅŸtirmeler

DÃ¼zeltmelerden sonra:
- âœ… Loss pozitif ve azalan olmalÄ±
- âœ… WER: 99.76% â†’ <30% (ilk epoch'ta)
- âœ… CER: 82.87% â†’ <15% (ilk epoch'ta)
- âœ… Model Ã¶ÄŸrenmeye baÅŸlamalÄ±

## ğŸ” Kontrol Listesi

EÄŸitim sÄ±rasÄ±nda kontrol edin:

1. **Loss deÄŸerleri**:
   - Pozitif olmalÄ±
   - Azalan trend gÃ¶stermeli
   - 0.5-5.0 arasÄ± normal

2. **Validation metrikleri**:
   - WER: Her epoch'ta azalmalÄ±
   - CER: Her epoch'ta azalmalÄ±
   - Loss: Training loss'a yakÄ±n olmalÄ±

3. **Veri kalitesi**:
   - Ses dosyalarÄ± yÃ¼kleniyor mu?
   - Transkriptler doÄŸru mu?
   - Label'lar doÄŸru encode ediliyor mu?

## ğŸ› Hala Sorun Varsa

EÄŸer hala yÃ¼ksek WER/CER varsa:

1. **Veri kontrolÃ¼**:
   ```bash
   # Ä°lk birkaÃ§ Ã¶rneÄŸi kontrol et
   head -5 data/users/Furkan/train.csv
   ```

2. **Model kontrolÃ¼**:
   ```bash
   # Model yÃ¼kleniyor mu?
   python3 -c "from transformers import Wav2Vec2ForCTC; print('OK')"
   ```

3. **Debug modu**:
   - Ä°lk batch'i yazdÄ±r
   - Label'larÄ± kontrol et
   - Input shape'leri kontrol et

## ğŸ“ Notlar

- Label encoding Ã§ok kritik - her Ã¶rnek ayrÄ± iÅŸlenmeli
- CTC loss iÃ§in -100 padding token'larÄ± Ã¶nemli
- Batch processing yerine individual processing daha gÃ¼venilir

