# Sunucu Optimizasyon KÄ±lavuzu - RTX A5000 + 48 CPU Ã‡ekirdek

## ğŸ–¥ï¸ Sistem Ã–zellikleri

- **CPU**: Intel Xeon E5-2670 v3 (48 Ã§ekirdek) @ 3.100GHz
- **GPU**: NVIDIA RTX A5000 (24GB VRAM)
- **Mimari**: Ampere (CUDA Compute Capability 8.6)

## âš¡ YapÄ±lan Optimizasyonlar

### 1. Batch Size Optimizasyonu

**Ã–nceki**: 4  
**Yeni**: 16  
**Efektif Batch Size**: 32 (16 Ã— 2 gradient accumulation)

RTX A5000'nin 24GB VRAM'i sayesinde batch size artÄ±rÄ±ldÄ±:
- Daha hÄ±zlÄ± eÄŸitim
- Daha stabil gradient hesaplama
- Daha iyi GPU kullanÄ±mÄ±

### 2. DataLoader Optimizasyonu

```python
DATALOADER_NUM_WORKERS = 8        # 48 Ã§ekirdek iÃ§in optimize
DATALOADER_PIN_MEMORY = True      # GPU'ya hÄ±zlÄ± transfer
DATALOADER_PREFETCH_FACTOR = 4    # Ã–nceden yÃ¼kleme
```

**Faydalar:**
- CPU-GPU veri transferi optimize edildi
- Veri yÃ¼kleme bottleneck'i azaltÄ±ldÄ±
- GPU idle time azaldÄ±

### 3. Veri Ã–n Ä°ÅŸleme ParalelleÅŸtirme

```python
DATA_PREPROCESSING_NUM_PROC = 16  # 48 Ã§ekirdeÄŸin 1/3'Ã¼
```

**Faydalar:**
- Veri Ã¶n iÅŸleme hÄ±zÄ± 4x arttÄ±
- CPU kaynaklarÄ± verimli kullanÄ±lÄ±yor
- EÄŸitim baÅŸlangÄ±Ã§ sÃ¼resi kÄ±saldÄ±

### 4. Mixed Precision (FP16)

```python
MIXED_PRECISION = "fp16"
```

**Faydalar:**
- ~2x hÄ±z artÄ±ÅŸÄ±
- ~50% VRAM tasarrufu
- RTX A5000 FP16'Ä± native destekliyor

### 5. Gradient Accumulation

**Ã–nceki**: 4  
**Yeni**: 2  

Daha bÃ¼yÃ¼k batch size ile gradient accumulation azaltÄ±ldÄ±:
- Daha hÄ±zlÄ± gÃ¼ncellemeler
- Daha iyi convergence
- Efektif batch size: 32 (optimal)

### 6. Gradient Checkpointing

```python
GRADIENT_CHECKPOINTING = False  # RTX A5000'de gerekli deÄŸil
```

24GB VRAM yeterli olduÄŸu iÃ§in checkpointing kapalÄ±:
- Daha hÄ±zlÄ± forward pass
- Daha az hesaplama overhead

## ğŸ“Š Performans Beklentileri

### EÄŸitim HÄ±zÄ±

**Ã–nceki Sistem (Batch 4, CPU-only preprocessing)**:
- ~2-3 Ã¶rnek/saniye
- Epoch sÃ¼resi: ~30-45 dakika (4000 Ã¶rnek iÃ§in)

**Yeni Sistem (RTX A5000, Batch 16, FP16)**:
- ~8-12 Ã¶rnek/saniye (4x hÄ±z artÄ±ÅŸÄ±)
- Epoch sÃ¼resi: ~7-10 dakika (4000 Ã¶rnek iÃ§in)
- **Toplam eÄŸitim sÃ¼resi: ~2-3 saat (20 epoch)**

### VRAM KullanÄ±mÄ±

- **Model**: ~2-3 GB
- **Batch 16 (FP16)**: ~4-6 GB
- **Gradient**: ~4-6 GB
- **Toplam**: ~10-15 GB / 24 GB (yaklaÅŸÄ±k %60 kullanÄ±m)

### CPU KullanÄ±mÄ±

- **Veri Ã¶n iÅŸleme**: 16 process (paralel)
- **DataLoader**: 8 worker
- **Toplam**: ~24-32 Ã§ekirdek aktif (48 Ã§ekirdeÄŸin %50-65'i)

## ğŸ”§ KonfigÃ¼rasyon AyarlarÄ±

### config.py OptimizasyonlarÄ±

```python
# Batch ve Gradient
FINETUNE_BATCH_SIZE = 16
GRADIENT_ACCUMULATION_STEPS = 2

# DataLoader
DATALOADER_NUM_WORKERS = 8
DATALOADER_PIN_MEMORY = True
DATALOADER_PREFETCH_FACTOR = 4

# Veri Ã–n Ä°ÅŸleme
DATA_PREPROCESSING_NUM_PROC = 16

# Mixed Precision
MIXED_PRECISION = "fp16"
```

## ğŸš€ KullanÄ±m

### EÄŸitim BaÅŸlatma

```bash
# Veri hazÄ±rlama
python prepare_training_data.py Furkan

# Model eÄŸitimi (RTX A5000 ile optimize)
python train_adapter.py Furkan
```

### Sistem Durumu KontrolÃ¼

EÄŸitim sÄ±rasÄ±nda ÅŸu bilgiler gÃ¶sterilir:
- GPU adÄ± ve VRAM miktarÄ±
- Mixed precision durumu
- Batch size ve efektif batch size
- CPU worker sayÄ±sÄ±

### Performans Ä°zleme

```bash
# GPU kullanÄ±mÄ±nÄ± izle
nvidia-smi -l 1

# CPU kullanÄ±mÄ±nÄ± izle
htop
```

## ğŸ“ˆ Optimizasyon SonuÃ§larÄ±

### HÄ±z Ä°yileÅŸtirmeleri

| Metrik | Ã–nceki | Yeni | Ä°yileÅŸtirme |
|--------|--------|------|-------------|
| Batch Size | 4 | 16 | 4x |
| Ã–rnek/Saniye | 2-3 | 8-12 | 4x |
| Epoch SÃ¼resi | 30-45 dk | 7-10 dk | 4-5x |
| Toplam SÃ¼re (20 epoch) | 10-15 saat | 2-3 saat | 5x |

### Kaynak KullanÄ±mÄ±

| Kaynak | KullanÄ±m | Durum |
|--------|----------|-------|
| GPU VRAM | ~15 GB / 24 GB | âœ… Optimal |
| GPU Compute | ~80-90% | âœ… Ä°yi |
| CPU Ã‡ekirdek | 24-32 / 48 | âœ… Ä°yi |
| CPU Memory | DeÄŸiÅŸken | âœ… Normal |

## âš ï¸ Dikkat Edilmesi Gerekenler

### 1. VRAM YÃ¶netimi

EÄŸer "CUDA out of memory" hatasÄ± alÄ±rsanÄ±z:
```python
# config.py'de batch size'Ä± azaltÄ±n
FINETUNE_BATCH_SIZE = 12  # veya 8
```

### 2. CPU Overload

EÄŸer sistem yavaÅŸlarsa:
```python
# Worker sayÄ±sÄ±nÄ± azaltÄ±n
DATALOADER_NUM_WORKERS = 4
DATA_PREPROCESSING_NUM_PROC = 8
```

### 3. Mixed Precision SorunlarÄ±

EÄŸer FP16'da sorun yaÅŸarsanÄ±z:
```python
MIXED_PRECISION = "no"  # FP32'ye geri dÃ¶n
```

## ğŸ¯ SonuÃ§

RTX A5000 ve 48 Ã§ekirdekli CPU iÃ§in sistem optimize edildi:

âœ… **4-5x daha hÄ±zlÄ± eÄŸitim**  
âœ… **Optimal GPU kullanÄ±mÄ±**  
âœ… **Verimli CPU paralelleÅŸtirme**  
âœ… **DÃ¼ÅŸÃ¼k VRAM kullanÄ±mÄ±**  
âœ… **Stabil ve gÃ¼venilir eÄŸitim**

Sistem artÄ±k sunucu donanÄ±mÄ±nÄ±zÄ± maksimum verimlilikle kullanÄ±yor!

