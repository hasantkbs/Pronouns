# -*- coding: utf-8 -*-
"""
KonuÅŸma BozukluÄŸu Ses TanÄ±ma Sistemi - Sentetik Veri OluÅŸturma AracÄ±

Bu script, `collect_word_data.py` ile toplanan tekil kelime kayÄ±tlarÄ±nÄ± kullanarak
sentetik cÃ¼mleler oluÅŸturur ve bunlarÄ± ana veri setine ekler.
Bu bir veri artÄ±rma (data augmentation) tekniÄŸidir.

KullanÄ±m:
- python augment_from_words.py user_001 --num-sentences 100
"""

import os
import pandas as pd
from pathlib import Path
import argparse
import random

try:
    from pydub import AudioSegment
except ImportError:
    print("âŒ Hata: pydub kÃ¼tÃ¼phanesi bulunamadÄ±.")
    print("LÃ¼tfen `pip install pydub` komutu ile kurun.")
    exit()

# --- YapÄ±landÄ±rma ---
BASE_DATA_PATH = "data/users"

def get_last_sentence_index(df):
    """Mevcut metadata'daki son 'sentence' index'ini bulur."""
    sentence_files = df[df['file_path'].str.contains("_sentence_")]
    if sentence_files.empty:
        return 0
    last_index = sentence_files['file_path'].str.extract(r'_sentence_(\d+).wav').astype(int).max().iloc[0]
    return last_index if pd.notna(last_index) else 0

def main():
    """Ana veri artÄ±rma fonksiyonu."""
    parser = argparse.ArgumentParser(description="Tekil kelimelerden sentetik veri oluÅŸturma aracÄ±.")
    parser.add_argument("user_id", type=str, help="Veri artÄ±rma yapÄ±lacak kullanÄ±cÄ±nÄ±n kimliÄŸi.")
    parser.add_argument("--num-sentences", type=int, required=True, help="OluÅŸturulacak sentetik cÃ¼mle sayÄ±sÄ±.")
    parser.add_argument("--min-words", type=int, default=3, help="Bir cÃ¼mlede olacak minimum kelime sayÄ±sÄ±.")
    parser.add_argument("--max-words", type=int, default=8, help="Bir cÃ¼mlede olacak maksimum kelime sayÄ±sÄ±.")
    args = parser.parse_args()

    # --- Dosya YollarÄ±nÄ± Ayarla ---
    user_path = Path(BASE_DATA_PATH) / args.user_id
    words_metadata_path = user_path / "metadata_words.csv"
    main_metadata_path = user_path / "metadata.csv"
    main_audio_path = user_path / "audio"

    # --- Gerekli DosyalarÄ± Kontrol Et ---
    if not words_metadata_path.exists():
        print(f"âŒ Hata: '{words_metadata_path}' bulunamadÄ±.")
        print("Ã–nce `collect_word_data.py` script'ini Ã§alÄ±ÅŸtÄ±rarak kelime verisi toplayÄ±n.")
        return

    main_audio_path.mkdir(parents=True, exist_ok=True)

    # --- Verileri YÃ¼kle ---
    print("Kelime verileri okunuyor...")
    word_df = pd.read_csv(words_metadata_path)
    
    if main_metadata_path.exists():
        main_df = pd.read_csv(main_metadata_path)
    else:
        main_df = pd.DataFrame(columns=["file_path", "transcription"])

    print(f"Toplam {len(word_df)} adet tekil kelime kaydÄ± bulundu.")

    # --- Sentetik CÃ¼mleleri OluÅŸtur ---
    print(f"\n{args.num_sentences} adet sentetik cÃ¼mle oluÅŸturuluyor...")
    
    new_metadata_rows = []
    last_augmented_index = main_df[main_df['file_path'].str.contains("_augmented_")]\
        .file_path.str.extract(r'_augmented_(\d+).wav').astype(int).max().iloc[0] if not main_df.empty and main_df[main_df['file_path'].str.contains("_augmented_")].any().any() else 0
    last_augmented_index = last_augmented_index if pd.notna(last_augmented_index) else 0

    for i in range(1, args.num_sentences + 1):
        num_words_to_combine = random.randint(args.min_words, args.max_words)
        
        # Rastgele kelimeler seÃ§
        sampled_words = word_df.sample(n=num_words_to_combine, replace=True)
        
        combined_audio = AudioSegment.empty()
        combined_transcription = []
        
        # Sesleri ve metinleri birleÅŸtir
        for _, row in sampled_words.iterrows():
            word_audio_path = Path(row['file_path'])
            if word_audio_path.exists():
                segment = AudioSegment.from_wav(word_audio_path)
                combined_audio += segment
                combined_transcription.append(row['transcription'])
            else:
                print(f"âš ï¸ UyarÄ±: '{word_audio_path}' bulunamadÄ±, atlanÄ±yor.")

        if not combined_audio:
            continue

        # Yeni dosyayÄ± ve metni oluÅŸtur
        new_transcription = " ".join(combined_transcription)
        new_index = last_augmented_index + i
        new_filename = f"{args.user_id}_augmented_{new_index}.wav"
        new_filepath = main_audio_path / new_filename
        
        # Sesi dÄ±ÅŸa aktar
        combined_audio.export(new_filepath, format="wav")
        
        new_metadata_rows.append({
            "file_path": str(new_filepath.absolute()),
            "transcription": new_transcription
        })
        
        print(f"OluÅŸturuldu ({i}/{args.num_sentences}): {new_filename} -> '{new_transcription}'")

    # --- Ana Metadata DosyasÄ±nÄ± GÃ¼ncelle ---
    if new_metadata_rows:
        new_rows_df = pd.DataFrame(new_metadata_rows)
        updated_df = pd.concat([main_df, new_rows_df], ignore_index=True)
        updated_df.to_csv(main_metadata_path, index=False, encoding='utf-8')

    print("\n" + "="*50)
    print("ğŸ‰ Veri artÄ±rma iÅŸlemi baÅŸarÄ±yla tamamlandÄ±!")
    print(f"Ana veri setine {len(new_metadata_rows)} adet sentetik cÃ¼mle eklendi.")
    print(f"GÃ¼ncel metadata dosyanÄ±z: {main_metadata_path}")

if __name__ == "__main__":
    main()
