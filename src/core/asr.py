

# -*- coding: utf-8 -*-
import torch
import torchaudio
import soundfile as sf
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
from pyctcdecode import build_ctcdecoder
from peft import PeftModel
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
import config

class ASRSystem:
    """
    KonuÅŸma BozukluÄŸu Ses TanÄ±ma Sistemi.
    Ses verisini metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, konuÅŸma bozukluÄŸu olan bireyler iÃ§in optimize edilmiÅŸtir.
    """
    def __init__(self, model_name: str = None, device: str = None):
        self.model_name = model_name or config.MODEL_NAME
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        print("ğŸ§ KonuÅŸma BozukluÄŸu Ses TanÄ±ma Sistemi baÅŸlatÄ±lÄ±yor...")
        print(f"ğŸ’» KullanÄ±lacak cihaz: {self.device}")

        try:
            # Check if the provided model_name is a directory (i.e., a personalized model path)
            is_personalized_model = os.path.isdir(self.model_name)

            if is_personalized_model:
                print(f"ğŸ“¥ Temel model '{config.MODEL_NAME}' yÃ¼kleniyor...")
                # 1. Load the base model
                self.processor = Wav2Vec2Processor.from_pretrained(config.MODEL_NAME)
                self.model = Wav2Vec2ForCTC.from_pretrained(config.MODEL_NAME).to(self.device)
                
                print(f"ğŸ¨ KiÅŸiselleÅŸtirilmiÅŸ adaptÃ¶r yÃ¼kleniyor: '{self.model_name}'")
                # 2. Load and apply the PEFT adapter
                self.model = PeftModel.from_pretrained(self.model, self.model_name)
                print("âœ¨ AdaptÃ¶r baÅŸarÄ±yla birleÅŸtirildi.")

            else:
                # Original behavior: load a model directly from Hugging Face hub
                print(f"ğŸ“¥ '{self.model_name}' modeli yÃ¼kleniyor...")
                self.processor = Wav2Vec2Processor.from_pretrained(self.model_name)
                self.model = Wav2Vec2ForCTC.from_pretrained(self.model_name).to(self.device)

            self.model.eval()
            print("âœ… ASR Modeli baÅŸarÄ±yla yÃ¼klendi.")
        except Exception as e:
            print(f"âŒ Hata: Model yÃ¼klenemedi. {e}")
            raise

        # Dil modelini yÃ¼kle (opsiyonel)
        self._load_decoder()

    def _load_decoder(self):
        """KenLM tabanlÄ± CTC decoder'Ä± yÃ¼kler (opsiyonel)."""
        self.decoder = None
        if not os.path.exists(config.KENLM_MODEL_PATH):
            print("\nâš ï¸  KenLM dil modeli bulunamadÄ±.")
            print(f"   Yol: '{config.KENLM_MODEL_PATH}'")
            print("   Dil modeli olmadan devam ediliyor (basit decoding).\n")
            return

        try:
            print("ğŸ“š Dil modeli (decoder) yÃ¼kleniyor...")
            vocab_dict = self.processor.tokenizer.get_vocab()
            sorted_vocab_list = sorted(vocab_dict.items(), key=lambda item: item[1])
            labels = [x[0] for x in sorted_vocab_list]
            
            # Harf bazlÄ± modellerde kelime ayÄ±rÄ±cÄ±yÄ± boÅŸluk yap
            labels[labels.index("|")] = " "

            self.decoder = build_ctcdecoder(
                labels=labels,
                kenlm_model_path=config.KENLM_MODEL_PATH,
            )
            print("âœ… Dil modeli baÅŸarÄ±yla yÃ¼klendi.")
        except Exception as e:
            print(f"âŒ Hata: Dil modeli yÃ¼klenemedi. {e}")
            self.decoder = None

    @torch.no_grad()
    def transcribe(self, audio_path: str) -> str:
        """
        Verilen ses dosyasÄ±nÄ± metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
        KonuÅŸma bozukluÄŸu olan bireyler iÃ§in optimize edilmiÅŸtir.

        Args:
            audio_path (str): Ses dosyasÄ±nÄ±n yolu

        Returns:
            str: TanÄ±nan metin
        """
        try:
            # Ses dosyasÄ±nÄ± oku
            speech_array, sampling_rate = sf.read(audio_path)
            
            # Ã–rnekleme oranÄ±nÄ± kontrol et ve gerekirse deÄŸiÅŸtir
            if sampling_rate != self.processor.feature_extractor.sampling_rate:
                resampler = torchaudio.transforms.Resample(
                    orig_freq=sampling_rate,
                    new_freq=self.processor.feature_extractor.sampling_rate
                )
                speech_array = resampler(torch.tensor(speech_array, dtype=torch.float)).numpy()

            # Ses verisini model iÃ§in hazÄ±rla
            input_values = self.processor(
                speech_array, 
                sampling_rate=self.processor.feature_extractor.sampling_rate, 
                return_tensors="pt", 
                padding=True
            ).input_values
            input_values = input_values.to(self.device)

            # Model tahmini
            logits = self.model(input_values).logits

            # DeÅŸifreleme
            if self.decoder:
                # Dil modeli ile beam search decoding (daha doÄŸru)
                transcription = self.decoder.decode(logits[0])
            else:
                # Basit greedy decoding
                predicted_ids = torch.argmax(logits, dim=-1)
                transcription = self.processor.batch_decode(predicted_ids)[0]
            
            # Metni temizle ve dÃ¶ndÃ¼r
            transcription = transcription.strip()
            return transcription

        except Exception as e:
            print(f"âŒ Hata: Ses dosyasÄ± iÅŸlenirken sorun oluÅŸtu. {e}")
            return ""

    def get_model_info(self) -> dict:
        """Model bilgilerini dÃ¶ndÃ¼rÃ¼r."""
        return {
            "model_name": self.model_name,
            "device": self.device,
            "has_language_model": self.decoder is not None,
            "sampling_rate": self.processor.feature_extractor.sampling_rate
        }

if __name__ == '__main__':
    asr_system = ASRSystem()
    # Ã–rnek kullanÄ±m iÃ§in geÃ§erli bir .wav dosyasÄ± yolu belirtin
    test_file = "users/speech_commands_test/on.wav" 
    if os.path.exists(test_file):
        print(f"\n--- ASR Testi BaÅŸlatÄ±lÄ±yor ---")
        print(f"Test dosyasÄ±: {test_file}")
        recognized_text = asr_system.transcribe(test_file)
        print(f"\nTest tamamlandÄ±.")
        print(f"TanÄ±nan metin: '{recognized_text}'")
    else:
        print(f"Test dosyasÄ± bulunamadÄ±: {test_file}")

