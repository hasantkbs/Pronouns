# evaluate_model.py

import os
import pandas as pd
import torch
import librosa
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
from datasets import Dataset, Audio
import evaluate
from pathlib import Path
import config
from tqdm import tqdm

class ModelEvaluator:
    def __init__(self, user_id, model_path=None):
        self.user_id = user_id
        self.personalized_model_dir = Path("data/models/personalized_models") / self.user_id
        self.data_path = Path(config.BASE_PATH) / self.user_id / "metadata_words.csv"
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        self.base_model_name = config.MODEL_NAME

        if self.personalized_model_dir.exists():
            self.model_to_load = str(self.personalized_model_dir)
            print(f"âœ… {self.user_id} iÃ§in kiÅŸiselleÅŸtirilmiÅŸ model yÃ¼klenecek: {self.model_to_load}")
        else:
            self.model_to_load = model_path or self.base_model_name
            print(f"â„¹ï¸  KiÅŸiselleÅŸtirilmiÅŸ model bulunamadÄ±. VarsayÄ±lan model kullanÄ±lacak: {self.model_to_load}")

        self.processor = Wav2Vec2Processor.from_pretrained(self.base_model_name)
        
        if self.personalized_model_dir.exists():
            from peft import PeftModel
            base_model = Wav2Vec2ForCTC.from_pretrained(self.base_model_name)
            self.model = PeftModel.from_pretrained(base_model, str(self.personalized_model_dir))
        else:
            self.model = Wav2Vec2ForCTC.from_pretrained(self.model_to_load)
            
        self.model.to(self.device)
        self.wer_metric = evaluate.load("wer")
        self.cer_metric = evaluate.load("cer")

    def prepare_dataset(self, max_samples=None):
        """
        DeÄŸerlendirme veri setini hazÄ±rlar.
        
        Args:
            max_samples: Maksimum Ã¶rnek sayÄ±sÄ± (None ise tÃ¼mÃ¼)
        
        Returns:
            Dataset veya None (hata durumunda)
        """
        # Ã–nce eval.csv'yi kontrol et
        eval_csv = Path(config.BASE_PATH) / self.user_id / "eval.csv"
        if eval_csv.exists():
            print(f"   âœ… eval.csv bulundu, kullanÄ±lÄ±yor.")
            df = pd.read_csv(eval_csv, encoding='utf-8')
        elif self.data_path.exists():
            print(f"   âš ï¸  eval.csv bulunamadÄ±, metadata_words.csv kullanÄ±lÄ±yor.")
            df = pd.read_csv(self.data_path, encoding='utf-8')
            df = df[['file_path', 'transcription']].copy()
            df.rename(columns={'transcription': 'transcript'}, inplace=True)
        else:
            print(f"âŒ Hata: Ne eval.csv ne de {self.data_path} bulunamadÄ±.")
            return None

        # Maksimum Ã¶rnek sayÄ±sÄ± sÄ±nÄ±rÄ±
        if max_samples and len(df) > max_samples:
            print(f"   âš ï¸  {len(df)} Ã¶rnek var, {max_samples} ile sÄ±nÄ±rlandÄ±rÄ±lÄ±yor.")
            df = df.head(max_samples)

        # Dosya yollarÄ±nÄ± dÃ¼zelt
        words_dir = Path(config.BASE_PATH) / self.user_id / "words"
        df["file_path"] = df["file_path"].apply(
            lambda x: str(words_dir / os.path.basename(str(x)))
        )
        
        # Var olmayan dosyalarÄ± filtrele
        original_size = len(df)
        df = df[df["file_path"].apply(os.path.exists)]
        if len(df) < original_size:
            print(f"   âš ï¸  {original_size - len(df)} adet bulunamayan ses dosyasÄ± atlandÄ±.")

        if len(df) == 0:
            print(f"âŒ Hata: HiÃ§ geÃ§erli ses dosyasÄ± bulunamadÄ±!")
            return None

        # Transcript sÃ¼tununu kontrol et
        transcript_col = 'transcript' if 'transcript' in df.columns else 'transcription'
        df = df[df[transcript_col].notna() & (df[transcript_col].str.strip() != '')]

        dataset = Dataset.from_pandas(df).cast_column(
            "file_path", 
            Audio(sampling_rate=config.ORNEKLEME_ORANI, decode=False)
        )
        
        print(f"   ğŸ“Š DeÄŸerlendirme seti: {len(dataset)} Ã¶rnek")
        return dataset

    def evaluate_model(self, dataset, max_samples=None):
        """
        Modeli deÄŸerlendirir ve WER/CER metriklerini hesaplar.
        
        Args:
            dataset: DeÄŸerlendirme veri seti
            max_samples: Maksimum deÄŸerlendirilecek Ã¶rnek sayÄ±sÄ±
        """
        if dataset is None:
            print("âŒ DeÄŸerlendirme veri seti yok!")
            return
        
        from torch.utils.data import DataLoader

        def collate_fn(batch):
            """Batch iÃ§in collate fonksiyonu."""
            audio_arrays = []
            reference_texts = []
            
            for item in batch:
                try:
                    audio, sr = librosa.load(
                        item['file_path']['path'], 
                        sr=config.ORNEKLEME_ORANI
                    )
                    if len(audio) > 0:
                        audio_arrays.append(audio)
                        # Transcript sÃ¼tununu kontrol et
                        transcript = item.get('transcript', item.get('transcription', ''))
                        reference_texts.append(str(transcript).strip())
                except Exception as e:
                    print(f"âš ï¸  Ses dosyasÄ± yÃ¼klenemedi: {e}")
                    continue
            
            if len(audio_arrays) == 0:
                return None
            
            input_features = self.processor(
                audio_arrays, 
                sampling_rate=config.ORNEKLEME_ORANI, 
                return_tensors="pt", 
                padding=True
            ).input_values
            
            return {
                "input_features": input_features, 
                "reference_texts": reference_texts
            }

        # RTX A5000 iÃ§in optimize edilmiÅŸ DataLoader
        dataloader = DataLoader(
            dataset, 
            batch_size=16,  # RTX A5000 iÃ§in artÄ±rÄ±ldÄ±
            collate_fn=collate_fn,
            num_workers=config.DATALOADER_NUM_WORKERS,
            pin_memory=config.DATALOADER_PIN_MEMORY,
            prefetch_factor=config.DATALOADER_PREFETCH_FACTOR if config.DATALOADER_NUM_WORKERS > 0 else None,
            persistent_workers=True if config.DATALOADER_NUM_WORKERS > 0 else False
        )

        predictions = []
        references = []

        print(f"\nğŸš€ {self.user_id} modeli deÄŸerlendiriliyor...")
        print(f"   Toplam kayÄ±t: {len(dataset)}")
        
        self.model.eval()
        processed_count = 0
        
        try:
            with torch.no_grad():
                for batch in tqdm(dataloader, desc="DeÄŸerlendirme"):
                    if batch is None:
                        continue
                    
                    input_features = batch["input_features"].to(self.device)

                    logits = self.model(input_features).logits
                    predicted_ids = torch.argmax(logits, dim=-1)
                    transcription = self.processor.batch_decode(
                        predicted_ids, 
                        skip_special_tokens=True
                    )

                    predictions.extend(transcription)
                    references.extend(batch["reference_texts"])
                    processed_count += len(batch["reference_texts"])
                    
                    if max_samples and processed_count >= max_samples:
                        break

            if len(predictions) == 0:
                print("âŒ HiÃ§ tahmin yapÄ±lamadÄ±!")
                return

            # Metrikleri hesapla
            wer = self.wer_metric.compute(
                predictions=predictions, 
                references=references
            )
            cer = self.cer_metric.compute(
                predictions=predictions, 
                references=references
            )

            print("\n" + "="*50)
            print(f"âœ… DeÄŸerlendirme TamamlandÄ±!")
            print(f"   Ä°ÅŸlenen Ã¶rnek: {len(predictions)}")
            print(f"   Word Error Rate (WER): {wer:.4f} ({wer*100:.2f}%)")
            print(f"   Character Error Rate (CER): {cer:.4f} ({cer*100:.2f}%)")
            print("="*50)
            
            # Ã–rnek tahminler gÃ¶ster
            if len(predictions) > 0:
                print("\nğŸ“ Ã–rnek Tahminler:")
                for i in range(min(5, len(predictions))):
                    print(f"   {i+1}. GerÃ§ek: '{references[i]}'")
                    print(f"      Tahmin: '{predictions[i]}'")
                    print()

            self.provide_suggestions(wer, cer)
            
        except Exception as e:
            print(f"\nâŒ DeÄŸerlendirme sÄ±rasÄ±nda hata: {e}")
            import traceback
            traceback.print_exc()

    def provide_suggestions(self, wer, cer):
        print("\nğŸ’¡ GeliÅŸtirme Ã–nerileri:")
        if wer > 0.3 or cer > 0.15: # Arbitrary thresholds for "poor" performance
            print("   - Daha fazla ve Ã§eÅŸitli veri toplayÄ±n.")
            print("   - `train_adapter.py` iÃ§indeki eÄŸitim parametrelerini (epoch, Ã¶ÄŸrenme oranÄ±) ayarlamayÄ± deneyin.")
        elif wer > 0.15 or cer > 0.05:
            print("   - Model performansÄ± iyi gÃ¶rÃ¼nÃ¼yor. Daha fazla veri ile daha da iyileÅŸtirilebilir.")
        else:
            print("   - Model performansÄ± oldukÃ§a baÅŸarÄ±lÄ±!")

import argparse

def main():
    parser = argparse.ArgumentParser(
        description="KiÅŸiselleÅŸtirilmiÅŸ ASR modelini deÄŸerlendirir."
    )
    parser.add_argument(
        "user_id", 
        type=str, 
        help="DeÄŸerlendirilecek kullanÄ±cÄ±nÄ±n kimliÄŸi (Ã¶rn: Furkan)"
    )
    parser.add_argument(
        "--max_samples",
        type=int,
        default=None,
        help="Maksimum deÄŸerlendirilecek Ã¶rnek sayÄ±sÄ± (varsayÄ±lan: tÃ¼mÃ¼)"
    )
    
    args = parser.parse_args()

    print("="*50)
    print(f"Model DeÄŸerlendirme: {args.user_id}")
    print("="*50)
    
    evaluator = ModelEvaluator(user_id=args.user_id)
    dataset = evaluator.prepare_dataset(max_samples=args.max_samples)
    if dataset:
        evaluator.evaluate_model(dataset, max_samples=args.max_samples)
    else:
        print("âŒ DeÄŸerlendirme yapÄ±lamadÄ±!")

if __name__ == "__main__":
    main()