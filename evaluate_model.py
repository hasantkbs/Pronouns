import os
import pandas as pd
import torch
import librosa
import soundfile as sf
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from datasets import Dataset, Audio
import evaluate
from pathlib import Path
import config

class ModelEvaluator:
    def __init__(self, user_id, model_path=None):
        self.user_id = user_id
        self.personalized_model_dir = Path("data/models/personalized_models") / self.user_id
        self.data_path = Path(config.BASE_PATH) / self.user_id / "metadata_words.csv"
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        if self.personalized_model_dir.exists():
            self.model_to_load = str(self.personalized_model_dir)
            print(f"âœ… {self.user_id} iÃ§in kiÅŸiselleÅŸtirilmiÅŸ model yÃ¼klenecek: {self.model_to_load}")
        else:
            self.model_to_load = model_path or "openai/whisper-base" # Default Whisper base model
            print(f"â„¹ï¸  KiÅŸiselleÅŸtirilmiÅŸ model bulunamadÄ±. VarsayÄ±lan model kullanÄ±lacak: {self.model_to_load}")

        self.processor = WhisperProcessor.from_pretrained(self.model_to_load if self.personalized_model_dir.exists() else "openai/whisper-base", language="tr", task="transcribe")
        
        if self.personalized_model_dir.exists():
            from peft import PeftModel
            base_model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")
            self.model = PeftModel.from_pretrained(base_model, str(self.personalized_model_dir))
        else:
            self.model = WhisperForConditionalGeneration.from_pretrained(self.model_to_load)
            
        self.model.to(self.device)
        self.wer_metric = evaluate.load("wer")
        self.cer_metric = evaluate.load("cer")

    def prepare_dataset(self):
        if not self.data_path.exists():
            print(f"âŒ Hata: {self.data_path} bulunamadÄ±. LÃ¼tfen doÄŸru yolu saÄŸlayÄ±n.")
            return None

        df = pd.read_csv(self.data_path)

        def audio_loader(path):
            filename = os.path.basename(path)
            filepath = Path(config.BASE_PATH) / self.user_id / "words" / filename
            speech, sample_rate = librosa.load(filepath, sr=config.ORNEKLEME_ORANI)
            return speech

        df["audio"] = df["file_path"].apply(audio_loader)
        dataset = Dataset.from_pandas(df)
        return dataset

    def evaluate_model(self, dataset):
        if dataset is None:
            return

        predictions = []
        references = []

        print(f"ğŸš€ {self.user_id} modeli deÄŸerlendiriliyor... (Toplam {len(dataset)} kayÄ±t)")
        self.model.eval()
        with torch.no_grad():
            for i, item in enumerate(dataset):
                audio_input = item["audio"]
                reference_text = item["transcription"]

                # Preprocess audio
                input_features = self.processor(audio_input, sampling_rate=config.ORNEKLEME_ORANI, return_tensors="pt").input_features
                input_features = input_features.to(self.device)

                # Generate transcription
                generated_ids = self.model.generate(inputs=input_features, language="tr", task="transcribe")
                transcription = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

                predictions.append(transcription)
                references.append(reference_text)
                
                print(f"[{i+1}/{len(dataset)}] Ref: '{reference_text}' | Pred: '{transcription}'")

        wer = self.wer_metric.compute(predictions=predictions, references=references)
        cer = self.cer_metric.compute(predictions=predictions, references=references)

        print("\n=========================================")
        print(f"âœ… DeÄŸerlendirme TamamlandÄ±!")
        print(f"   Word Error Rate (WER): {wer:.4f}")
        print(f"   Character Error Rate (CER): {cer:.4f}")
        print("=========================================")
        print("\nâš ï¸  Not: Bu deÄŸerlendirme eÄŸitim verisi Ã¼zerinde yapÄ±lmÄ±ÅŸtÄ±r ve modelin gerÃ§ek performansÄ±nÄ± yansÄ±tmayabilir.")

        self.provide_suggestions(wer, cer)

    def provide_suggestions(self, wer, cer):
        print("\nğŸ’¡ GeliÅŸtirme Ã–nerileri:")
        if wer > 0.3 or cer > 0.15: # Arbitrary thresholds for "poor" performance
            print("   - Daha fazla ve Ã§eÅŸitli veri toplayÄ±n. Ã–zellikle modelin zorlandÄ±ÄŸÄ± kelimeler/cÃ¼mleler Ã¼zerinde yoÄŸunlaÅŸÄ±n.")
            print("   - KayÄ±t ortamÄ±nÄ±n kalitesini artÄ±rÄ±n (daha az gÃ¼rÃ¼ltÃ¼, daha iyi mikrofon).")
            print("   - `personalize_model.py` iÃ§indeki eÄŸitim parametrelerini (epoch sayÄ±sÄ±, Ã¶ÄŸrenme oranÄ±) ayarlamayÄ± deneyin.")
            print("   - EÄŸer model hala kÃ¶tÃ¼ performans gÃ¶steriyorsa, daha gÃ¼Ã§lÃ¼ bir temel ASR modeli araÅŸtÄ±rmayÄ± dÃ¼ÅŸÃ¼nebilirsiniz.")
        elif wer > 0.15 or cer > 0.05: # Arbitrary thresholds for "moderate" performance
            print("   - Model performansÄ± iyi gÃ¶rÃ¼nÃ¼yor. Daha fazla veri ile daha da iyileÅŸtirilebilir.")
            print("   - Ã–zellikle yanlÄ±ÅŸ tanÄ±nan kelimeleri analiz ederek bu kelimeler iÃ§in ek veri toplayabilirsiniz.")
            print("   - Dil modeli (KenLM) entegrasyonunu kontrol edin veya daha gÃ¼Ã§lÃ¼ bir dil modeli kullanmayÄ± dÃ¼ÅŸÃ¼nÃ¼n.")
        else:
            print("   - Model performansÄ± oldukÃ§a baÅŸarÄ±lÄ±! Daha fazla iyileÅŸtirme iÃ§in Ã§ok spesifik hatalara odaklanÄ±labilir.")
            print("   - FarklÄ± konuÅŸma hÄ±zlarÄ± veya tonlamalar iÃ§in ek veri toplayarak genellenebilirliÄŸi artÄ±rabilirsiniz.")

import argparse

def main():
    parser = argparse.ArgumentParser(description="KiÅŸiselleÅŸtirilmiÅŸ ASR modelini deÄŸerlendirir.")
    parser.add_argument("user_id", type=str, help="DeÄŸerlendirilecek kullanÄ±cÄ±nÄ±n kimliÄŸi.")
    args = parser.parse_args()

    evaluator = ModelEvaluator(user_id=args.user_id)
    dataset = evaluator.prepare_dataset()
    if dataset:
        evaluator.evaluate_model(dataset)

if __name__ == "__main__":
    # Set environment variable for MPS fallback if on Apple Silicon
    os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
    main()
